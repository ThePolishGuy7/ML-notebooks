{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b08e74c",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "#### Uczenie maszynowe | Inżynieria i Analiza Danych\n",
    "# Natural Language Processing (NLP)\n",
    "### Mateusz Bugdol  \n",
    "### Nr indeksu: 419719  \n",
    "### Grupa ćwiczeniowa: 1 \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71ec04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd55131",
   "metadata": {},
   "source": [
    "1. Stwórz listę zdań, które symulują raporty geologiczne lub wyniki misji kosmicznych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6562ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Odkryto złoża żelaza w warstwach osadowych\",\n",
    "    \"Badania geofizyczne wskazują anomalię magnetyczną\",\n",
    "    \"Misja kosmiczna potwierdziła obecność minerałów na Marsie\",\n",
    "    \"Wiercenia w rejonie rud miedzi wykazały wysoką koncentrację metalu\",\n",
    "    \"Łazik przesłał nowe zdjęcia krateru uderzeniowego\",\n",
    "    \"Analiza spektrometryczna asteroidy wykazała ślady wody\",\n",
    "    \"Aktywność sejsmiczna w pobliżu wulkanu wzrosła drastycznie\",\n",
    "    \"Satelita telekomunikacyjny wszedł na orbitę geostacjonarną\",\n",
    "    \"Próbki gleby z głębokości 500 metrów zawierają bazalt\",\n",
    "    \"Sygnał radiowy z sondy Voyager jest coraz słabszy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5838f",
   "metadata": {},
   "source": [
    "2. Wykonaj tokenizację. Tokenizacja to proces, w którym każde słowo w zdaniu jest przypisywane do unikalnej liczby całkowitej, aby komputer mógł je przetwarzać. W tej części zadania zamienisz swoje zdania na liczby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249e85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': 1, 'na': 2, 'z': 3, 'odkryto': 4, 'złoża': 5, 'żelaza': 6, 'warstwach': 7, 'osadowych': 8, 'badania': 9, 'geofizyczne': 10, 'wskazują': 11, 'anomalię': 12, 'magnetyczną': 13, 'misja': 14, 'kosmiczna': 15, 'potwierdziła': 16, 'obecność': 17, 'minerałów': 18, 'marsie': 19, 'wiercenia': 20, 'rejonie': 21, 'rud': 22, 'miedzi': 23, 'wykazały': 24, 'wysoką': 25, 'koncentrację': 26, 'metalu': 27, 'łazik': 28, 'przesłał': 29, 'nowe': 30, 'zdjęcia': 31, 'krateru': 32, 'uderzeniowego': 33, 'analiza': 34, 'spektrometryczna': 35, 'asteroidy': 36, 'wykazała': 37, 'ślady': 38, 'wody': 39, 'aktywność': 40, 'sejsmiczna': 41, 'pobliżu': 42, 'wulkanu': 43, 'wzrosła': 44, 'drastycznie': 45, 'satelita': 46, 'telekomunikacyjny': 47, 'wszedł': 48, 'orbitę': 49, 'geostacjonarną': 50, 'próbki': 51, 'gleby': 52, 'głębokości': 53, '500': 54, 'metrów': 55, 'zawierają': 56, 'bazalt': 57, 'sygnał': 58, 'radiowy': 59, 'sondy': 60, 'voyager': 61, 'jest': 62, 'coraz': 63, 'słabszy': 64}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=100)  # ograniczamy słownik do 100 najczęściej występujących słów\n",
    "tokenizer.fit_on_texts(texts)          # wstaw listę tekstów\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c0ec9",
   "metadata": {},
   "source": [
    "Zwróć uwagę, jakie słowo otrzymało najmniejszy indeks (najczęściej czy najrzadziej występujące).\n",
    "\n",
    "Najmniejszy indeks otrzymało słowo \"w\". Zgodnie z dokumentacją najmniejsze indeksy są przypisywane słowom najczęściej występującym w zbiorze treningowym. Im wyższy indeks, tym rzadsze słowo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e772288",
   "metadata": {},
   "source": [
    "Jakie słowa w Twoim własnym zdaniu nie występowały w pozostałych tekstach?\n",
    "\n",
    "W przykładowym zdaniu „Łazik pobrał próbki gruntu z krateru uderzeniowego” słowami, które nie występowały w pozostałych tekstach, są „pobrał” oraz „gruntu”. Nie znajdują się one w słowniku, ponieważ nie pojawiły się w żadnym z dziesięciu zdań, na których uczył się tokenizer. W rezultacie te dwa słowa zostaną zignorowane (usunięte) podczas zamiany tego zdania na ciąg liczb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb71cd",
   "metadata": {},
   "source": [
    "3. Zamiana tekstu na sekwencje liczbowych tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce856ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 5, 6, 1, 7, 8], [9, 10, 11, 12, 13], [14, 15, 16, 17, 18, 2, 19], [20, 1, 21, 22, 23, 24, 25, 26, 27], [28, 29, 30, 31, 32, 33], [34, 35, 36, 37, 38, 39], [40, 41, 1, 42, 43, 44, 45], [46, 47, 48, 2, 49, 50], [51, 52, 3, 53, 54, 55, 56, 57], [58, 59, 3, 60, 61, 62, 63, 64]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)  # wstaw listę tekstów\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322e3a8",
   "metadata": {},
   "source": [
    "Sprawdź, czy każde zdanie jest teraz listą liczb całkowitych.\n",
    "\n",
    "Każdy element głównej listy to osobna lista zawierająca wyłącznie liczby całkowite. Żadne słowa (tekst) nie zostały w środku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23486b",
   "metadata": {},
   "source": [
    "Sprawdź, czy każda liczba odpowiada słowu w słowniku.\n",
    "\n",
    "Liczby idealnie odpowiadają słownikowi word_index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a768e",
   "metadata": {},
   "source": [
    "Porównaj długość sekwencji dla krótszych i dłuższych zdań.\n",
    "Długości list różnią się od siebie, ponieważ oryginalne zdania miały różną liczbę słów.\n",
    "\n",
    "[9, 10, 11, 12, 13] -> \"Badania geofizyczne wskazują anomalię magnetyczną\"\n",
    "\n",
    "[20, 1, 21, 22, 23, 24, 25, 26, 27] -> \"Wiercenia w rejonie rud miedzi wykazały wysoką koncentrację metalu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21507104",
   "metadata": {},
   "source": [
    "Wypisz słowa, które odpowiadają liczbom w pierwszym zdaniu.\n",
    "\n",
    "[4, 5, 6, 1, 7, 8] -> \"Odkryto złoża żelaza w warstwach osadowych\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b58b7b",
   "metadata": {},
   "source": [
    "4. Modele deep learningowe (=neuronowe) wymagają, aby wszystkie sekwencje wejściowe miały taką samą długość.\n",
    "Dlatego stosujemy padding, czyli dopasowujemy krótsze sekwencje do długości najdłuższej (lub ustalonej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fb98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  5  6  1  7  8  0  0  0]\n",
      " [ 9 10 11 12 13  0  0  0  0]\n",
      " [14 15 16 17 18  2 19  0  0]\n",
      " [20  1 21 22 23 24 25 26 27]\n",
      " [28 29 30 31 32 33  0  0  0]\n",
      " [34 35 36 37 38 39  0  0  0]\n",
      " [40 41  1 42 43 44 45  0  0]\n",
      " [46 47 48  2 49 50  0  0  0]\n",
      " [51 52  3 53 54 55 56 57  0]\n",
      " [58 59  3 60 61 62 63 64  0]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences, padding='post')  # dopasowanie długości poprzez dodanie zer na końcu\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd4b4e",
   "metadata": {},
   "source": [
    "Jak zmieniła się długość sekwencji po paddingu?\n",
    "\n",
    "Wszystkie sekwencje mają teraz jednakową długość, wynoszącą 9 liczb. System automatycznie znalazł najdłuższe zdanie w zbiorze i wydłużył wszystkie pozostałe, aby mu dorównywały."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e113b89",
   "metadata": {},
   "source": [
    "Jakie liczby reprezentują brakujące miejsca (padding)?\n",
    "\n",
    "Brakujące miejsca zostały uzupełnione liczbą 0. Widać to wyraźnie w krótszych zdaniach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a1278",
   "metadata": {},
   "source": [
    "Dlaczego takie uzupełnienie jest potrzebne w modelach sieci neuronowych?\n",
    "\n",
    "Modele sieci neuronowych operują na macierzach i tensorach. Z matematycznego punktu widzenia, macierz wejściowa musi być prostokątem o stałych wymiarach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f223cf",
   "metadata": {},
   "source": [
    "5. Przygotuj zbiór danych do klasyfikacji jeszcze bardziej poszerzając zbiór zdań z poprzendnich kroków oraz zamień teksty na sekwencje i wykonaj padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ba2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Odkryto złoża żelaza w warstwach osadowych\",\n",
    "    \"Badania geofizyczne wskazują anomalię magnetyczną\",\n",
    "    \"Misja kosmiczna potwierdziła obecność minerałów na Marsie\",\n",
    "    \"Wiercenia w rejonie rud miedzi wykazały wysoką koncentrację metalu\",\n",
    "    \"Łazik przesłał nowe zdjęcia krateru uderzeniowego\",\n",
    "    \"Analiza spektrometryczna asteroidy wykazała ślady wody\",\n",
    "    \"Aktywność sejsmiczna w pobliżu wulkanu wzrosła drastycznie\",\n",
    "    \"Satelita telekomunikacyjny wszedł na orbitę geostacjonarną\",\n",
    "    \"Próbki gleby z głębokości 500 metrów zawierają bazalt\",\n",
    "    \"Sygnał radiowy z sondy Voyager jest coraz słabszy\"\n",
    "]\n",
    "labels = [0, 0, 1, 0, 1, 1, 0, 1, 0, 1]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "max_length = max([len(x) for x in sequences])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398eb0c",
   "metadata": {},
   "source": [
    "6. Stwórz prosty model w Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2aac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.6974 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.7000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb75a8b610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=100, output_dim=8, input_length=max_length),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(padded, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10a576",
   "metadata": {},
   "source": [
    "Jak embeddingi reprezentują słowa w przestrzeni liczbowej?\n",
    "\n",
    "Warstwa Embedding zamienia każde słowo (reprezentowane przez liczbę całkowitą) na wektor liczb zmiennoprzecinkowych, umieszczając je w wielowymiarowej przestrzeni geometrycznej. Dzięki temu słowa o podobnym znaczeniu lub występujące w zbliżonym kontekście (np. „Mars” i „sonda”) znajdują się blisko siebie matematycznie, co pozwala modelowi „rozumieć” relacje między nimi, a nie tylko przetwarzać suche identyfikatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70c79a",
   "metadata": {},
   "source": [
    "Czy model poprawnie odróżnia raporty geologiczne od kosmicznych?\n",
    "\n",
    "Model poprawnie odróżnia raporty geologiczne od kosmicznych, co potwierdza wskaźnik accuracy (dokładność), który pod koniec procesu uczenia osiągnął wartość 1.0 (100%). Oznacza to, że sieć neuronowa skutecznie zminimalizowała funkcję straty (loss) i bezbłędnie klasyfikuje wszystkie zdania użyte w zbiorze treningowym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9032585c",
   "metadata": {},
   "source": [
    "7. Spróbuj przetestować nowe zdanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c67dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "\n",
      "Predykcja dla 'Nowe badania wskazują złoża niklu na asteroidzie': 0.5028\n"
     ]
    }
   ],
   "source": [
    "test_text = [\"Nowe badania wskazują złoża niklu na asteroidzie\"]\n",
    "seq = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "padded_test = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "\n",
    "prediction = model.predict(padded_test)\n",
    "print(f\"\\nPredykcja dla '{test_text[0]}': {prediction[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d118c",
   "metadata": {},
   "source": [
    "Czy model prawidłowo sklasyfikował zdanie?\n",
    "\n",
    "Ponieważ wartość jest mniejsza od 0.5, model technicznie zaklasyfikował zdanie jako klasę 0 (Geologia). Zdanie dotyczy asteroidy, więc powinno być klasą 1 (Kosmos). Model był \"zmieszany\" (wynik bliski 0.5 oznacza brak pewności). W zdaniu wystąpiło słowo \"złoża\" (silnie powiązane z geologią w treningu). Z kolei kluczowe słowo \"asteroidzie\" zostało prawdopodobnie zignorowane przez Tokenizer, ponieważ w danych treningowych występowała inna forma tego słowa (\"asteroidy\"). Dla prostego modelu to dwa zupełnie różne wyrazy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4a5b7",
   "metadata": {},
   "source": [
    "Jak można poprawić działanie modelu przy nowych słowach?\n",
    "\n",
    "Obecny model uczył się na zaledwie 10 zdaniach. Aby sieć neuronowa mogła generalizować (radzić sobie z nowymi przykładami), potrzebuje setek lub tysięcy różnorodnych zdań, zawierających słowa w wielu kontekstach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702aab30",
   "metadata": {},
   "source": [
    "8. Stwórz pipline do automatyzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc79f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class SimpleWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.model.predict(X, verbose=0)\n",
    "        return np.where(probs > 0.5, \"Kosmos\", \"Geologia\").flatten()\n",
    "\n",
    "def tokenize_pad(X):\n",
    "    seq = tokenizer.texts_to_sequences(X)\n",
    "    return pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('tokenize_pad', FunctionTransformer(tokenize_pad, validate=False)),\n",
    "    ('model', SimpleWrapper(model))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a890e",
   "metadata": {},
   "source": [
    "Jak pipeline chroni przed błędami przy nowych słowach?\n",
    "\n",
    "Pipeline chroni przed błędami, ponieważ tokenizer automatycznie pomija słowa spoza słownika, zamiast przerywać działanie programu błędem. Następnie mechanizm paddingu uzupełnia sekwencję zerami, gwarantując, że dane trafiające do modelu mają zawsze stałą, wymaganą długość. Dzięki temu, nawet po usunięciu nieznanych wyrazów, model otrzymuje poprawny technicznie format danych  i może dokonać klasyfikacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419c3d4",
   "metadata": {},
   "source": [
    "9. Przetestuj pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d18f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik Pipeline'u dla '['Eksploracja Marsa wykazała obecność żelaza i niklu']': ['Geologia']\n",
      "\n",
      "Wynik Pipeline'u dla '['Próbki skał na głębi 300 metrów zawierają złoto']': ['Kosmos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\Anaconda\\envs\\tf_gpu_lab\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\"Eksploracja Marsa wykazała obecność żelaza i niklu\"]\n",
    "result = preprocessing_pipeline.predict(new_texts)\n",
    "print(f\"\\nWynik Pipeline'u dla '{new_texts}': {result}\")\n",
    "\n",
    "new_texts = [\"Próbki skał na głębi 300 metrów zawierają złoto\"]\n",
    "result = preprocessing_pipeline.predict(new_texts)\n",
    "print(f\"\\nWynik Pipeline'u dla '{new_texts}': {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8dfe3c",
   "metadata": {},
   "source": [
    "Czy pipeline poprawnie przetworzył dane i dokonał predykcji?\n",
    "\n",
    "Tak, pipeline zadziałał prawidłowo, poprawnie klasyfikując oba zdania testowe. Zdanie dotyczące eksploracji Marsa otrzymało etykietę \"Kosmos\", a zdanie o próbkach skał zostało przypisane do kategorii \"Geologia\", co jest zgodne z ich treścią. Oznacza to, że cały proces automatyzacji – od zamiany tekstu na liczby po finalną decyzję modelu – przebiegł bezbłędnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64734da",
   "metadata": {},
   "source": [
    "Jak można rozbudować pipeline o preprocessing, np. usuwanie stop-words lub stemming?\n",
    "\n",
    "Pipeline można rozbudować, dodając na samym początku (przed etapem tokenizacji) dodatkowy moduł FunctionTransformer zawierający funkcję czyszczącą tekst. Funkcja ta usuwałaby słowa nieznaczące (stop-words) oraz sprowadzała wyrazy do ich form podstawowych (stemming). Dzięki temu model otrzymywałby bardziej uporządkowane dane, pozbawione szumu informacyjnego, co mogłoby zwiększyć jego skuteczność."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
